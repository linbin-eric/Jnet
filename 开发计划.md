# 目标

新设计解码器，HttpReqPartDecoder，可以部分参考HttpRequestDecoder，实现对 Http 协议的解析。

## 核心思路

1. 在解码器内部解析出所有的 header，放入HttpReqHead。头部识别完毕后，传递给后面的处理器。
2. 解码器接着解码Http的 body 部分，每次读取到多少，就包装为HttpReqBodyPart，传递给后面的处理器。
3. 当 body 解析完成后，生成HttpReqEnd，传递给后面的处理器。然后可以开始处理下一个 http 请求。

## 详细实现思路

1. HttpReqPartDecoder 继承 AbstractDecoder，复用其 accumulation 缓冲区管理和数据累积逻辑。
2. 使用状态机模式，定义五个状态：REQUEST_LINE（解析请求行）、REQUEST_HEADER（解析头部）、BODY_FIX_LENGTH（固定长度body）、BODY_CHUNKED（chunked编码body）、NO_BODY（无body）。
3. 请求行解析：查找第一个 \r\n，解析出 method、url、version。
4. 头部解析：查找 \r\n\r\n 标记头部结束，使用 HttpDecodeUtil.findAllHeaders 解析所有 header。头部解析完成后，构建 HttpReqHead 并通过 next.fireRead() 传递。
5. Body 类型判断：
   - 如果有 Content-Length 且大于 0，进入 BODY_FIX_LENGTH 状态
   - 如果有 Transfer-Encoding: chunked，进入 BODY_CHUNKED 状态
   - 否则进入 NO_BODY 状态，直接生成 HttpReqEnd
6. 固定长度 Body 解析：每次有数据到达时，将当前可读数据切片为 HttpReqBodyPart 传递给后续处理器，累计已读取的 body 长度。当已读取长度等于 Content-Length 时，生成 HttpReqEnd。
7. Chunked Body 解析：解析每个 chunk 的大小行（十六进制数字 + \r\n），读取对应长度的数据包装为 HttpReqBodyPart 传递。当遇到大小为 0 的 chunk 时，生成 HttpReqEnd。

## 实施步骤

### 步骤1：完善 HttpReqHead 类

在 `src/main/java/cc/jfire/jnet/extend/http/dto/HttpReqHead.java` 中添加 addHeader 方法和 chunked 标记：

```java
protected boolean chunked = false;

public void addHeader(String name, String value)
{
    headers.put(name, value);
}
```

### 步骤2：创建 HttpReqPartDecoder 类

在 `src/main/java/cc/jfire/jnet/extend/http/coder/HttpReqPartDecoder.java` 创建新类：

```java
package cc.jfire.jnet.extend.http.coder;

import cc.jfire.jnet.common.api.ReadProcessorNode;
import cc.jfire.jnet.common.coder.AbstractDecoder;
import cc.jfire.jnet.common.util.HttpDecodeUtil;
import cc.jfire.jnet.extend.http.dto.HttpReqBodyPart;
import cc.jfire.jnet.extend.http.dto.HttpReqEnd;
import cc.jfire.jnet.extend.http.dto.HttpReqHead;

import java.nio.charset.StandardCharsets;

public class HttpReqPartDecoder extends AbstractDecoder
{
    private static final int MAX_CHUNK_SIZE_LINE_LENGTH = 32;
    private int         lastCheck = -1;
    private ParseState  state     = ParseState.REQUEST_LINE;
    private HttpReqHead reqHead;
    private int         bodyRead  = 0;
    private int         chunkSize = -1;

    @Override
    protected void process0(ReadProcessorNode next)
    {
        boolean goToNextState;
        do
        {
            goToNextState = switch (state)
            {
                case REQUEST_LINE -> parseRequestLine();
                case REQUEST_HEADER -> parseRequestHeader(next);
                case BODY_FIX_LENGTH -> parseBodyFixLength(next);
                case BODY_CHUNKED -> parseBodyChunked(next);
                case NO_BODY ->
                {
                    next.fireRead(new HttpReqEnd());
                    resetState();
                    yield accumulation != null && accumulation.remainRead() > 0;
                }
            };
        } while (goToNextState);
    }

    private boolean parseRequestLine()
    {
        if (lastCheck == -1)
        {
            lastCheck = accumulation.getReadPosi();
        }
        for (; lastCheck + 1 < accumulation.getWritePosi(); lastCheck++)
        {
            if (accumulation.get(lastCheck) == '\r' && accumulation.get(lastCheck + 1) == '\n')
            {
                lastCheck += 2;
                state = ParseState.REQUEST_HEADER;
                break;
            }
        }
        if (state == ParseState.REQUEST_HEADER)
        {
            reqHead = new HttpReqHead();
            decodeRequestLine();
            return true;
        }
        return false;
    }

    private void decodeRequestLine()
    {
        for (int i = accumulation.getReadPosi(); i < lastCheck; i++)
        {
            if (accumulation.get(i) == ' ')
            {
                reqHead.setMethod(StandardCharsets.US_ASCII.decode(accumulation.readableByteBuffer(i)).toString());
                accumulation.setReadPosi(i + 1);
                break;
            }
        }
        for (int i = accumulation.getReadPosi(); i < lastCheck; i++)
        {
            if (accumulation.get(i) == ' ')
            {
                reqHead.setUrl(StandardCharsets.US_ASCII.decode(accumulation.readableByteBuffer(i)).toString());
                accumulation.setReadPosi(i + 1);
                break;
            }
        }
        for (int i = accumulation.getReadPosi(); i < lastCheck; i++)
        {
            if (accumulation.get(i) == '\r')
            {
                reqHead.setVersion(StandardCharsets.US_ASCII.decode(accumulation.readableByteBuffer(i)).toString());
                break;
            }
        }
        accumulation.setReadPosi(lastCheck);
    }

    private boolean parseRequestHeader(ReadProcessorNode next)
    {
        for (; lastCheck + 3 < accumulation.getWritePosi(); lastCheck++)
        {
            if (accumulation.get(lastCheck) == '\r' && accumulation.get(lastCheck + 1) == '\n'
                && accumulation.get(lastCheck + 2) == '\r' && accumulation.get(lastCheck + 3) == '\n')
            {
                lastCheck = -1;
                HttpDecodeUtil.findAllHeaders(accumulation, reqHead::addHeader);
                HttpDecodeUtil.findContentLength(reqHead.getHeaders(), reqHead::setContentLength);
                parseBodyType();
                next.fireRead(reqHead);
                return true;
            }
        }
        return false;
    }

    private void parseBodyType()
    {
        if (reqHead.getContentLength() > 0)
        {
            state = ParseState.BODY_FIX_LENGTH;
        }
        else
        {
            boolean hasTransferEncoding = reqHead.getHeaders().entrySet().stream()
                .anyMatch(e -> e.getKey().equalsIgnoreCase("Transfer-Encoding") && e.getValue().equalsIgnoreCase("chunked"));
            if (hasTransferEncoding)
            {
                state = ParseState.BODY_CHUNKED;
                reqHead.setChunked(true);
            }
            else
            {
                state = ParseState.NO_BODY;
            }
        }
    }

    private boolean parseBodyFixLength(ReadProcessorNode next)
    {
        if (accumulation == null || accumulation.remainRead() == 0)
        {
            return false;
        }
        int left = reqHead.getContentLength() - bodyRead;
        int remain = accumulation.remainRead();
        if (remain > left)
        {
            HttpReqBodyPart part = new HttpReqBodyPart();
            part.setPart(accumulation.slice(left));
            next.fireRead(part);
            next.fireRead(new HttpReqEnd());
            resetState();
            return accumulation != null && accumulation.remainRead() > 0;
        }
        else if (remain == left)
        {
            HttpReqBodyPart part = new HttpReqBodyPart();
            part.setPart(accumulation);
            accumulation = null;
            next.fireRead(part);
            next.fireRead(new HttpReqEnd());
            resetState();
            return false;
        }
        else
        {
            bodyRead += remain;
            HttpReqBodyPart part = new HttpReqBodyPart();
            part.setPart(accumulation);
            accumulation = null;
            next.fireRead(part);
            return false;
        }
    }

    private boolean parseBodyChunked(ReadProcessorNode next)
    {
        if (chunkSize == -1)
        {
            for (int i = accumulation.getReadPosi(); i < accumulation.getWritePosi() - 1; i++)
            {
                if (i - accumulation.getReadPosi() > MAX_CHUNK_SIZE_LINE_LENGTH)
                {
                    throw new IllegalStateException("Chunk size line exceeds " + MAX_CHUNK_SIZE_LINE_LENGTH + " bytes");
                }
                if (accumulation.get(i) == '\r' && accumulation.get(i + 1) == '\n')
                {
                    chunkSize = Integer.parseInt(StandardCharsets.US_ASCII.decode(accumulation.readableByteBuffer(i)).toString().trim(), 16);
                    accumulation.setReadPosi(i + 2);
                    break;
                }
            }
        }
        if (chunkSize == -1)
        {
            return false;
        }
        if (chunkSize == 0)
        {
            if (accumulation.remainRead() < 2)
            {
                return false;
            }
            accumulation.addReadPosi(2);
            next.fireRead(new HttpReqEnd());
            resetState();
            return accumulation != null && accumulation.remainRead() > 0;
        }
        if (accumulation.remainRead() < chunkSize + 2)
        {
            return false;
        }
        HttpReqBodyPart part = new HttpReqBodyPart();
        part.setPart(accumulation.slice(chunkSize));
        accumulation.addReadPosi(2);
        next.fireRead(part);
        chunkSize = -1;
        return true;
    }

    private void resetState()
    {
        reqHead = null;
        bodyRead = 0;
        chunkSize = -1;
        state = ParseState.REQUEST_LINE;
        if (accumulation != null && accumulation.remainRead() == 0)
        {
            accumulation.free();
            accumulation = null;
        }
    }

    enum ParseState
    {
        REQUEST_LINE, REQUEST_HEADER, NO_BODY, BODY_FIX_LENGTH, BODY_CHUNKED
    }
}
```

## 待办列表

1. 完善 HttpReqHead 类，添加 addHeader 方法和 chunked 字段
2. 创建 HttpReqPartDecoder 类

## 需要修改或新增的类

1. **修改**: `cc.jfire.jnet.extend.http.dto.HttpReqHead` - 添加 addHeader 方法和 chunked 字段
2. **新增**: `cc.jfire.jnet.extend.http.coder.HttpReqPartDecoder` - 新的分段 HTTP 请求解码器
